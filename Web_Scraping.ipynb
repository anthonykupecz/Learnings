{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Set up required libraries"
      ],
      "metadata": {
        "id": "zSWV5LV7twXT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRzcteogsu-d",
        "outputId": "7f0911e2-0676-489b-e56c-7c3d188d7e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install beautifulsoup4\n",
        "!pip install requests\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "html_doc = \"\"\"\n",
        "<html><head><title>The Dormouse's story</title></head>\n",
        "<body>\n",
        "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
        "\n",
        "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
        "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
        "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
        "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
        "and they lived at the bottom of a well.</p>\n",
        "\n",
        "<p class=\"story\">...</p>\n",
        "\"\"\"\n",
        "\n",
        "soup = BeautifulSoup(html_doc)"
      ],
      "metadata": {
        "id": "TzSgm5bLsyZm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(soup.prettify())"
      ],
      "metadata": {
        "id": "wsxnnOKwtyDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting a tag from the object\n",
        "# Gets the first occurence\n",
        "head = soup.head\n",
        "print(head)\n",
        "\n",
        "\n",
        "# To get all occurrences, use the find all method\n",
        "anchors = soup.find_all('a')\n",
        "\n",
        "# Extract all urls\n",
        "urls = []\n",
        "\n",
        "for anchor in anchors:\n",
        "  urls.append(anchor.get('href'))\n",
        "\n",
        "print(urls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FznHJ7UMuNE9",
        "outputId": "92bfa6fc-277a-46b0-8b20-303dfd3f25c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<head><title>The Dormouse's story</title></head>\n",
            "['http://example.com/elsie', 'http://example.com/lacie', 'http://example.com/tillie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrape reddit homepage"
      ],
      "metadata": {
        "id": "ZrSxXFQ8zwlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "html = requests.get(\"http://ibm.com\")\n",
        "soup = BeautifulSoup(html.text)\n",
        "\n",
        "for link in soup.find_all('a',href=True):  # in html anchor/link is represented by the tag <a>\n",
        "\n",
        "    print(link.get('href'))\n",
        "\n",
        "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n",
        "    print(link)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ersnSsaaz14H",
        "outputId": "5d983b27-078e-4f01-dca5-7f36d671234f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://www.ibm.com/hybrid-cloud?lnk=hpUSbt1\n",
            "https://www.ibm.com/consulting\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for link in soup.find_all('img'):# in html image is represented by the tag <img>\n",
        "    print(link)"
      ],
      "metadata": {
        "id": "hv-PLLSQ0E7q"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CQ86JCw1Lbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}